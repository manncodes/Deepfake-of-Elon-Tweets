{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "elontweets",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "506f4b97-ddc7-42c6-e4b7-152f51d85d7a"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE",
        "colab_type": "text"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "f575c89f-717a-43e5-eb90-9fb17f60ac71"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun 17 15:50:26 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "473e59ec-95f1-40cb-ad90-30f69073d735"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 228Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 90.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 256Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:03, 161Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 306Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 154Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 117Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0485ff15-cadb-43ad-ad97-d63454208f6e"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"elontweets.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34486b52-7a55-4ad5-defc-7591b27a5f20"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  1.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 87229 tokens\n",
            "Training...\n",
            "[10 | 52.80] loss=3.91 avg=3.91\n",
            "[20 | 97.70] loss=3.49 avg=3.69\n",
            "[30 | 142.53] loss=3.60 avg=3.66\n",
            "[40 | 187.37] loss=3.42 avg=3.60\n",
            "[50 | 232.17] loss=3.43 avg=3.56\n",
            "[60 | 276.95] loss=3.08 avg=3.48\n",
            "[70 | 321.71] loss=2.89 avg=3.39\n",
            "[80 | 366.47] loss=3.02 avg=3.35\n",
            "[90 | 411.23] loss=2.58 avg=3.26\n",
            "[100 | 456.00] loss=2.21 avg=3.15\n",
            "[110 | 500.73] loss=1.95 avg=3.03\n",
            "[120 | 545.46] loss=2.42 avg=2.98\n",
            "[130 | 590.21] loss=2.11 avg=2.91\n",
            "[140 | 634.95] loss=1.57 avg=2.81\n",
            "[150 | 679.73] loss=1.64 avg=2.72\n",
            "[160 | 724.46] loss=1.75 avg=2.66\n",
            "[170 | 769.20] loss=1.58 avg=2.59\n",
            "[180 | 813.95] loss=1.29 avg=2.51\n",
            "[190 | 858.68] loss=1.10 avg=2.43\n",
            "[200 | 903.42] loss=0.91 avg=2.35\n",
            "======== SAMPLE 1 ========\n",
            " it for a second and you should too.\n",
            "This is the end result of careful calibration and refinement by @elonmusk. Really good @F9 team. Key improvements include: more control over pitch and feel of hexacopter arc\n",
            "@ID_AA_Carmack pretty much\n",
            "@ID_AA_Carmack loud and clear\n",
            "@ID_AA_Carmack that's the point\n",
            "@karlbrauer sure :)\n",
            "@karaswisher You are correct that the pitch control was poor. It was worse than some believe, but not as much as some may want to believe. All that matters is that people confuse pitch and feel they are moving away from the hexacopter arc. No system goes above .01% or below.\n",
            "High res version at 1.29MB. Updated hexacopter arc control and pitch pitch pitch pitch pitch in next few days.\n",
            "@ID_AA_Carmack yay!\n",
            "@ID_AA_Carmack o.o\n",
            "RT @OpenAI: A video tutorial for Elon Musk's keynote addresses in 2 to 3 minutes: https://t.co/NyUgM5h5hU.\n",
            "@id_AA_Carmack that's what we are to speak from the beginning\n",
            "@ID_AA_Carmack I've written three books already, so this would be about time\n",
            "@ID_AA_Carmack Good point :)\n",
            "@ID_AA_Carmack Yeah, controller lag is something we can adjust, but not as much as other software. Just a more serious issue with software.\n",
            "@ID_AA_Carmack A more serious one, but that is becoming more serious in complexity +\n",
            "@JonHermaly We are working on fixing it right now, but hard work is no doubt needed\n",
            "@ID_AA_Carmack Not specifically, but two key points:\n",
            "1. Latency optimised for short periods of time, while being mobile & fast (no server traffic)\n",
            "2. Alt+tab key used extensively in Tesla software\n",
            "Testing on hands-free mode now underway. Hoping for Alpha this week.\n",
            "@vicentes @plugshare Trying this out myself right now! Might improve for you.\n",
            "Can't believe I made it this far. I'm done. 1st flight in ~60 hours of my plan to test out VTOL. Ready to go anywhere.\n",
            "@Benzinga Been going through this myself, so far it's almost self-explanatory (no hardware changes)\n",
            "@plugshare Trying it as my first Tesla drive and it works. Really well!\n",
            "@sctimes breakfast is key, as is going to be breakfast at home. A 12:9 aspect ratio breakfast for lunch is super important.\n",
            "@plugshare @TeslaMotors breakfast is almost done! Preparing for tomorrow's Autolist breakfast!\n",
            "@nickbilton will do\n",
            "\n",
            "Our favorite Model X videos, sorted by most inspiring:<|endoftext|>About\n",
            "\n",
            "The goal of the Kickstarter is to raise $30,000 by end of September to complete the Kickstarter campaign! Goal of 1k by end of July!\n",
            "\n",
            "Tesla Powerwalls are capable of holding a city size Tesla Model S on city streets at max payload. Highly configurable, this can easily be upgraded to max range at any time via webcast! https://t.co/dGVpeKfONg\n",
            "\n",
            "This awesome video of SpaceX launching a satellite will win a Nobel Prize soon https://t.co/cj6WVAU0LK\n",
            "\n",
            "https://t.co/Y5b5c8jz3b\n",
            "\n",
            "The irony is oh no, this won't work\n",
            "\n",
            "A French toast to the creative genius behind Tesla Powerpacks https://t.co/6DQD6Dm0L4b\n",
            "\n",
            "@ponder664 @reddit It can be incredibly boring being a tech nerd. Maybe try something new.?\n",
            "@ChromeOS It can.\n",
            "@ethereum @batasrvids Yes, but it is actually\n",
            "You can set your home button shade to amber (for winter) or grey (for summer). I like the look.\n",
            "@batasrvids Yes\n",
            "@andrewfisker @reddit It can be incredibly boring being a tech nerd. Maybe try something new.?\n",
            "@ChromeOS It can. Tesla recommends turning it off in the tv, but it does so pretty well on the dark woods\n",
            "@AndrewFisker @reddit It can be extremely boring being a tech nerd. Maybe try something new.?\n",
            "@batasrvids Maybe red, green or blue, but vodka tastes a lot like vodka\n",
            "@mehrenfeldtmeh @ryybuzz it has none\n",
            "Just wanted to thank David and Rocco for creating the Tesla Powerpack initiative https://t.co/Wcs4\n",
            "\n",
            "[210 | 965.91] loss=1.20 avg=2.29\n",
            "[220 | 1010.64] loss=1.17 avg=2.23\n",
            "[230 | 1055.40] loss=0.96 avg=2.17\n",
            "[240 | 1100.12] loss=0.70 avg=2.10\n",
            "[250 | 1144.87] loss=0.65 avg=2.03\n",
            "[260 | 1189.63] loss=0.72 avg=1.98\n",
            "[270 | 1234.40] loss=0.65 avg=1.92\n",
            "[280 | 1279.15] loss=0.59 avg=1.87\n",
            "[290 | 1323.89] loss=0.73 avg=1.82\n",
            "[300 | 1368.64] loss=0.46 avg=1.77\n",
            "[310 | 1413.38] loss=0.31 avg=1.72\n",
            "[320 | 1458.13] loss=0.32 avg=1.66\n",
            "[330 | 1502.87] loss=0.49 avg=1.62\n",
            "[340 | 1547.64] loss=0.31 avg=1.58\n",
            "[350 | 1592.41] loss=0.29 avg=1.53\n",
            "[360 | 1637.13] loss=0.30 avg=1.49\n",
            "[370 | 1681.85] loss=0.17 avg=1.45\n",
            "[380 | 1726.61] loss=0.14 avg=1.41\n",
            "[390 | 1771.31] loss=0.09 avg=1.37\n",
            "[400 | 1816.03] loss=0.12 avg=1.33\n",
            "======== SAMPLE 1 ========\n",
            ".\n",
            "@nickg_uk already taken over by vods and will gradually get more like vp5\n",
            "@Fanta_Popov in a few months\n",
            "@Recode Dex will do\n",
            "@ID_AA_Carmack roughly. Probably upper niece w 1st, but i.e. most common 3 will be the 2 we have now.\n",
            "@_amprobably Alright, fair enough!\n",
            "Start work on the HW2 Autopilot filter module today. It is HUGE, so will probably need doing first.\n",
            "@id_AA_Carmack @_ChrisUant time\n",
            "Testing of the new HW2 Autopilot filter. Seems to be doing what it's supposed to do best: speed up the test. We're going from 1.6GB to 2.0GB here.\n",
            "@_ChrisUant Nothing majorly wrong with the code. It just needs a few minor refactoring to make it run on new hardware.\n",
            "@Mikey67_FB Good point :)\n",
            "6.1 release candidate. Will give HW2 half the performance of past 6.x. Wish it was that long.\n",
            "@_Very_Goody There are several dozen that are probably bigger...\n",
            "There is only one HW2 compute compute compute\n",
            "Major improvements / regressions to be tested by @GigaOptic (after which I will make major improvements wless schedule auto tuning)\n",
            "@_dr_vs The ~20% figure is only for a small segment of market, where ~60% to 80% of consumers already own a car.\n",
            "High end cars are coming too, not least because of their fast autopilot. People want a car that can take them anywhere.\n",
            "@athletic_models No problem for cars 3 to 5. Even ultrafast (1.6) are enough to get me running again.\n",
            "@athletic_model People think high def, but in reality, range is surprisingly low. Even moderate range gain would be a good thing\n",
            "@Dave_Yatussama Highest I've ever been. Alarm bells go off in upper ranges.\n",
            "@Jon_Favreau Range increases when firing larger amounts of ammunition. Most modern semi-automatic rifles have ranges of up to 150 km.\n",
            "@bobbyblackstock Early adopters of HW2. This is me, running 7 cars before settling for 0+2 as my max.\n",
            "@FBeuster Yes, it was a difficult day for us, as the Tesla fleet matures, as product product growth is constrained.\n",
            "While the Gigafactory proves that having words is always a bad idea, there is a way.\n",
            "@JeffMcIntosh The press on Autopilot has been abysmal. So much so that I missed a ride last week.\n",
            "@jeffmason16 It's not limited to media. Just doesn't sound like the same policy should be applied to all.\n",
            "Regarding non press conferences. Slew job listing wrong. Next job posting likely will be from now.\n",
            "Hang on for thoughtful ...we will run out of press conferences tonight. LMA* think we can do more.\n",
            "@visakanv One day. Or maybe three. Either way, it's enough for now.\n",
            "Important to note that this is not a blog per se. This is an attempt to be anti-spam. A blog is not actually a surveillance state.\n",
            "Here's how to report a spy bug:\n",
            "Report any spy bug via  spam@thegov.tm\n",
            "RT @ The Guardian: There is talk of establishing a military HQ in Virginia in the near future #Tesla Is Almost Certainly There https://t.co/OzclfmSpQhh\n",
            "US govt tests fire of new Autopilot feature for US traffic delays https://t.co/ajlky5GMP6\n",
            "@ marcus calder foundation: trust is the best disinfectant ❤\n",
            "RT @ govt.gov: we're releasing the first version of Voice over LTE for Model S. Available for $99k & soon for iPhone & iPad. https://t.co?\n",
            "@ knollaert We are expanding that to cover all regions of the country\n",
            "Faced with a massive mobile shortfall, the US military created Voice over US. Simulations show Deep Web with very little customer success.\n",
            "Wi-Fi reliability and high levels of backup was also good, but encountered some issues. Will cover all regions of the country\n",
            "There is no guarantee that a Tesla will make it to Model S, but there is probability of a Model 3 being successful. Model 3's are a necessary but not enough to doom it all.\n",
            "RT @ Model S: The battery is charging! @ellejtimon https://t.co/xtkUR0pI9z\n",
            "@ Elite review Model S can get a good bang for buck when deployed selflessly towards packs. Single camera optimization expected.\n",
            "@ @Space\n",
            "\n",
            "[410 | 1877.17] loss=0.13 avg=1.30\n",
            "[420 | 1921.94] loss=0.11 avg=1.26\n",
            "[430 | 1966.71] loss=0.08 avg=1.23\n",
            "[440 | 2011.41] loss=0.06 avg=1.20\n",
            "[450 | 2056.13] loss=0.08 avg=1.16\n",
            "[460 | 2100.83] loss=0.09 avg=1.14\n",
            "[470 | 2145.46] loss=0.06 avg=1.11\n",
            "[480 | 2189.92] loss=0.09 avg=1.08\n",
            "[490 | 2234.30] loss=0.07 avg=1.05\n",
            "[500 | 2278.73] loss=0.07 avg=1.03\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 2326.39] loss=0.08 avg=1.01\n",
            "[520 | 2370.87] loss=0.07 avg=0.98\n",
            "[530 | 2415.33] loss=0.09 avg=0.96\n",
            "[540 | 2459.89] loss=0.06 avg=0.94\n",
            "[550 | 2504.60] loss=0.06 avg=0.92\n",
            "[560 | 2549.37] loss=0.07 avg=0.90\n",
            "[570 | 2594.08] loss=0.07 avg=0.88\n",
            "[580 | 2638.85] loss=0.06 avg=0.86\n",
            "[590 | 2683.61] loss=0.06 avg=0.84\n",
            "[600 | 2728.32] loss=0.06 avg=0.83\n",
            "======== SAMPLE 1 ========\n",
            "ab\n",
            "@B_Rans yes\n",
            "@visiting @motherjulius Easier to make the plane change to equatorial rack. Really big body needed, but moves much better.\n",
            "@_jeremys Cool ?\n",
            "@visiting @motherjulius @BrianDunning Exactly\n",
            "RT @SpaceX: Close, but no cigar here. Sorry about that. I looked cool. Future is here. https://t.co/1dGVJBcSg4\n",
            "@perky_cobra @BrianDunning Exactly\n",
            "@kasabuji That's why I'm against anti-aging lip balm. May contain titanium (Frag4l).\n",
            "@jhaaa There is no way. A drop in volume will affect recall. 4K playback would be a good thing.\n",
            "@bakamoto Some places may require adjustment of tint coating. Per Hays filing suit.\n",
            "@RobertGaristo @nikkiam Model 3 RWD can record 1080p, read 400+ chars its interior and 2160p via rear camera, but only @B_Rans has the camera rolling\n",
            "@garisto reads rapidly by an Englishman during a day. His pace is not spreching.\n",
            "@soswow yay! good feedback!\n",
            "@MacTechGenius +1 would be a good target. Would take suggestions from peers in Model 3 group consensus to heart.\n",
            "@skyshop79 simple answer is that it's better to emphasize the important details of the car over the next update.\n",
            "@skyshop79 writing about software often conflates functionality with customization. So versioning an existing feature with ? is even worse.\n",
            "@skyshop79 We greatly appreciate your input! Looking forward to making the Model 3 experience as good as possible.\n",
            "@skyshop79 New interface is smooth and intuitive. Looks like a robot is holding up a message. Engines are set to ARMv7.\n",
            "@ocashlandingstar @RyanDeKort @RyanHummer I'm going to work full time today to do my shift at Tesla.\n",
            "@VoltzCoreAudio @RyanDeKort @RyanHummer @CDrivetmann Tomorrow is a bit of a blur, of course\n",
            "@scottmcnealy That would definitely help\n",
            "@ddkilzer @RyanDeKort @RyanHummer @scottmcnealy Tesla will contact store owner\n",
            "@ArminKeyani All publicly known Tesla product developments will be focused on the Model 3, including Autopilot. Only sedan, not X product.\n",
            "@mjmdavis @keithmcmc @cdrj1ll Really? Ok, I will work harder on thinking first and tweeting second.\n",
            "@keithmcmc @cdrj1ll I think so\n",
            "@cdrj1ll Model 3 will be $250k incrementally. Down the road maybe $100k if all goes well.\n",
            "@vigneshraju a lot of people have asked if I'd like to do a movie sequel to My 2013. I said yes, that's what matters\n",
            "@RanRinBC JJ Abrams' Star Trek: Next Generation was great and I hope they make a great movie.\n",
            "@rikreddine Yes\n",
            "@MikeMfra My kids and I are having a great time!\n",
            "@Leo{3}Dron{3} are scientists at The Ohio State University, who are trying to understand the physics behind the 'Chandelier effect.' http://t.co/t1VQGfQMD\n",
            "@PernilleJ @Zybbby @CFinneyNEXT @monster — @CFinneyNEXT (@monster) June 29, 2013\n",
            "@kilzer2150 Mostly snowing, but maybe a little more in Vancouver Hillcrest. Beyond that, it's a very different place.\n",
            "@grid_square Good point :)\n",
            "@LaurenShearer1 Nothing beats The Boring Company album. No matter what genre of song they put out, 1989 is the year of The Company.\n",
            "@TobiasVdb Yeah, that has been my goal from the beginning. Continued beyond that.\n",
            "@MusexCalendar I think I'm going to die from the impact, actually\n",
            "@RocciottaSomething No, I will remain on the coast doing original soundtrack. May change at any time.\n",
            "@LewisBlackBeret Possibly one of my favorite jobs. A daily grind job with little pay, overtime and sick days is my favorite.\n",
            "@CJMRBC @LewisBlackBeret I've never worked for a superannuation company. I've never written an article for an investment company.\n",
            "@TheHedgehog @mashable likely true\n",
            "@qzI777 I don't know what the hell am I doing\n",
            "@RealBenCamperance Really don't have to be this way\n",
            "@R\n",
            "\n",
            "[610 | 2789.51] loss=0.05 avg=0.81\n",
            "[620 | 2834.27] loss=0.06 avg=0.79\n",
            "[630 | 2878.98] loss=0.05 avg=0.78\n",
            "[640 | 2923.68] loss=0.06 avg=0.76\n",
            "[650 | 2968.36] loss=0.07 avg=0.75\n",
            "[660 | 3013.07] loss=0.05 avg=0.73\n",
            "[670 | 3057.82] loss=0.06 avg=0.72\n",
            "[680 | 3102.59] loss=0.05 avg=0.71\n",
            "[690 | 3147.31] loss=0.06 avg=0.69\n",
            "[700 | 3192.09] loss=0.05 avg=0.68\n",
            "[710 | 3236.78] loss=0.05 avg=0.67\n",
            "[720 | 3281.54] loss=0.05 avg=0.66\n",
            "[730 | 3326.31] loss=0.06 avg=0.64\n",
            "[740 | 3371.02] loss=0.05 avg=0.63\n",
            "[750 | 3415.74] loss=0.04 avg=0.62\n",
            "[760 | 3460.49] loss=0.05 avg=0.61\n",
            "[770 | 3505.18] loss=0.05 avg=0.60\n",
            "[780 | 3549.93] loss=0.05 avg=0.59\n",
            "[790 | 3594.45] loss=0.05 avg=0.58\n",
            "[800 | 3638.98] loss=0.05 avg=0.57\n",
            "======== SAMPLE 1 ========\n",
            "co@TheEconomist http://t.?\n",
            "If you care about coral, sign off on Kinder Morgan Trans Mountain (this will be 1.3 million km2), Amazon's massive parcel and much more http://t.co/MmQl6cAXWl\n",
            "Rough cut of Falcon 9 presentation to investors http://t.co/jOwclS96Yr\n",
            "$1B funding target by end of 2015, i.e. beginning of cycles earlier http://t.co/XtMWTD9xC\n",
            "Promising conversations with @MayorOfLA regarding the use of the new #Millivolotrillion energy source http://t.co/jOwysqudXk\n",
            "S.O.G.E.T.S.E. vid of rocket meeting energy standards at Cape Canaveral http://t.co/C9ZuMys3fha\n",
            "Btw, 99% probably true prob not 98%. The probability of an error is +1, so a false positive would be severe.\n",
            " 99%+ chance of an errorsign on our part, but I've never seen a sign off like this before\n",
            "@inversedotcom No such thing as true precedent, so follow up by police, fire or sea or both.\n",
            "@wfederman @inversedotcom We certainly could, but there is no way.\n",
            "@inversedotcom Def not ok. Just needs to be clear that the tweet is a judicial one, not a scientific one.\n",
            "The idea of lasers being used to destroy Elon Musk's spaceship is not new. However, the Fermi Paradox suggests that there may be a whole other dimension to this story\n",
            "@simonhackett Yes, but that's judicial\n",
            "Some interesting speculation about Judge Paullerg effect: https://t.co/cYuUouJAsZ\n",
            "If all looks good, the DC grid would be static between now and then. That is, no before, after and after photos.\n",
            "@SmileSimplify @beboutside @ChristieC @pimpo84 @Chris_Cistull @nottshopefully\n",
            "Tesla drive is 1000+ miles in 4 months, so time to test new tech. Details: https://t.co/p4HrKN0O16\n",
            "@nottshopefully Still possible that some kind of geoengineering is used to create a barrier around the missile, but o? https://t.co/v4hA6zIKqz\n",
            "@beboutside @Chris_Cistull @nottshopefully\n",
            "@cerulv for sure\n",
            "@ReesAndersen The missile will land in Mexico, but the route is more underground than 1st, so it will be differently shaped.\n",
            "@ReesAndersen Similar route for carvco deliveries, but with rail (plaid) and underground (black/red)\n",
            "@amerpro555 I love America\n",
            "The_Grainer Interesting https://t.co/eiUR2NSQ5m\n",
            "@amerpro555 I love America\n",
            "@Krishell1989 Easy switch to Canada, Mexico & Africa. Will switch to Tesla in the meantime.\n",
            "@rishell1989 Not difficult to find stores with the right team. Best selling Sonic the Hedgehog.\n",
            "@bestselling Author Gary games master plan through the 80s. Sonic the Hedgehog is my favorite video game.\n",
            "@Excellioner That's why I like Gary so much. Good mindgames.\n",
            "@Slate They are true. Good companies that built great companies often have money in scams.\n",
            "@Slate They are mostly right, but there are also a few misinformed people out there.\n",
            "In general, people exaggerate the power of exaggerating or undercounting events. This is especially true of smaller events.\n",
            "@BArtusio One of my sons is named Xavier. He is a hero to many, but I am sure he will like it\n",
            "@mariom An amazing headgear!\n",
            "@BArtusio Yes, the cape and maggot cloaking the body are the same\n",
            "@SwiftOnSecurity I love Gary and his team. I'm proud of the effort that went into creating the car.\n",
            "@SwiftOnSecurity Gary and his team have solo experience, but the X is definitely a bigger deal than some people think\n",
            "@AstroOrionMK @SwiftOnSecurity Gary and his team have a lot of tools and a great team, but the game UI isn't well thought through\n",
            "@SwiftOnSecurity Gary and his team have a lot of experience with netdecking and other complex vehicles, but the car is no closer\n",
            "@wdavidtayar Only about 400 lbs max. Can take kids!\n",
            "@wdavidtayar This is super r/AAA though, so u guys die for, or epic robot vs mech supercar. I\n",
            "\n",
            "[810 | 3699.69] loss=0.06 avg=0.56\n",
            "[820 | 3744.04] loss=0.05 avg=0.55\n",
            "[830 | 3788.53] loss=0.05 avg=0.54\n",
            "[840 | 3833.02] loss=0.05 avg=0.54\n",
            "[850 | 3877.43] loss=0.06 avg=0.53\n",
            "[860 | 3921.86] loss=0.04 avg=0.52\n",
            "[870 | 3966.31] loss=0.06 avg=0.51\n",
            "[880 | 4010.79] loss=0.04 avg=0.50\n",
            "[890 | 4055.25] loss=0.05 avg=0.50\n",
            "[900 | 4099.69] loss=0.05 avg=0.49\n",
            "[910 | 4144.17] loss=0.05 avg=0.48\n",
            "[920 | 4188.65] loss=0.05 avg=0.47\n",
            "[930 | 4233.14] loss=0.04 avg=0.47\n",
            "[940 | 4277.60] loss=0.06 avg=0.46\n",
            "[950 | 4322.05] loss=0.04 avg=0.45\n",
            "[960 | 4366.48] loss=0.05 avg=0.45\n",
            "[970 | 4410.91] loss=0.04 avg=0.44\n",
            "[980 | 4455.33] loss=0.04 avg=0.43\n",
            "[990 | 4499.83] loss=0.05 avg=0.43\n",
            "[1000 | 4544.30] loss=0.05 avg=0.42\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9f50b85d-d70a-4f50-ba7a-8e23f67cf560"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "57988f80-b901-4039-d7f4-032c55f1b064"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My favorite shot of the Falcon 9 launch window from the last flight of the Falcon Heavy booster https://t.co/9EPrgfYQz\n",
            "RT @SpaceX: Falcon 9 has successfully deployed Falcon Heavy to its target orbit. Launch window opens at 10:32 am EDT, 15:32 UTC. https://t.co/9EPrgfYQz\n",
            "RT @SpaceX: Successful deployment of #Dragon to its target orbit. Hope you have as well. https://t.co/bn7c3LYaU3\n",
            "@redletterdave Good point, odds go from 0% to >0% :)\n",
            "Falcon 9 deployed to full max over Pacific Ocean https://t.co/TbT2kVkZwJ\n",
            "@oxfordteddy Browser is already a little better. Kernel and browser update in prob 6 weeks or so.\n",
            "RT @SpaceX: Weather 60% go for #Falcon9 launch today. More ... https://t.co/gtC39uBC7z\n",
            "@SpaceX_ launch window opens Sunday, 1st of next gen Falcon 9. Weather 60% go for #Dragon test flight. https://t.co/gtC39uBC7z\n",
            "RT @SpaceX: #Dragon is now vertical in advance of Sunday, 1st launch of the next-generation Falcon 9 https://t.co/gtC39uBC7z https://t.co/j?\n",
            "@CapnJesus @Lurpatron @MKBHD @jakerawr 3 is a great car, but definitely Model S\n",
            "@kyleugh Good point\n",
            "@PriyancaFord I wish. It's so annoying.\n",
            "Finally, an explanation for daylight savings that makes sense ... https://t.co/kGpJHNgRJO\n",
            "@AndreElijah Ok\n",
            "@BizbuilderUSA @mcannonbrookes It's been a bear to get done, but prob 10 days or so, depending on full speed autosteer test results\n",
            "@Legit_bacon @mcannonbrookes Looking forward to it. I know it's cliche, but LotR is my favorite book ever :) Want t? https://t.co/uchiQ0kZuc\n",
            "@5AllanLeVito @mcannonbrookes @VGroysman Sure. Just check out my prior tweet on pricing ($250 kWh at pack level). W? https://t.co/eJ1c60MkYc\n",
            "@mcannonbrookes Can only happen with your support, and working closely with key govt and utility leaders who are s? https://t.co/AlfAGI0kLB\n",
            "Just wanted to write a note of appreciation to the many Australians who came out in support of the battery plan, especially @mcannonbrookes\n",
            "@ah_pton16 I love Wikipedia. Just gets better over time.\n",
            "@JMMZHerrera Answer is complex for electric motors. We use an AC induction motor fed by a DC pack thru an IGBT inve? https://t.co/uKsjIDZPAq\n",
            "@williamwinters High voltage DC is for sure the best way to transmit electricity over long distances. Good explanat? https://t.co/Ucz8O3Tfm1\n",
            "Ironically, direct current is the right approach today, even though alternating was right in the past. Solar power & electronics both DC.\n",
            "You're most welcome. Very exciting to discuss the future of electricity. Renewables + storage arguably biggest disr? https://t.co/czUfwZkgJE\n",
            "@mcannonbrookes Just spoke with @JayWeatherill, Premier of South Australia. Very impressed. Govt is clearly committ? https://t.co/JNOCwKVMxY\n",
            "@shails Yes, but shipping, taxes/tariffs and installation labor vary by country, as those costs are beyond our control\n",
            "@mcannonbrookes $250/kWh at the pack level for 100MWh+ systems. Tesla is moving to fixed and open pricing and terms for all products.\n",
            "@mcannonbrookes Tesla will get the system installed and working 100 days from contract signature or it is free. That serious enough for you?\n",
            "@Zedd Will send you one\n",
            "@SimonaKitzu Self-hatred\n",
            "Thanks JJ!\n",
            "https://t.co/3YSXZq1EVj\n",
            "RT @TeslaMotors: Project Loveday https://t.co/K1snXJN15u\n",
            "Thank you for the lovely letter. That sounds like a great idea. We'll do it! https://t.co/ss2WmkOGyk\n",
            "SpaceX could not do this without NASA. Can't express enough appreciation. https://t.co/uQpI60zAV7\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "35fb1a4d-11c9-48ed-9ef7-8c7a14572868"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              truncate='https:',\n",
        "              length=150,\n",
        "              temperature=0.89,\n",
        "              prefix=\"humans\",\n",
        "              nsamples = 5,\n",
        "              top_k=20,             \n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "humans, it has been a great couple of months ?\n",
            "RT @SpaceX: More photos from today?s Falcon 9 launch and first stage landing ? https://t.co/095WHWMtKp https://t.co/TpFnWS9GI9\n",
            "RT @TeslaMotors: Our new Supercharger route in South Australia will soon allow Tesla owners to visit the world's largest battery site https?\n",
            "@SmileSimplify Fun, exciting tweets coming soon!\n",
            "@SmileSimplify Sorry about that. You're right. I was depressing myself too :(\n",
            "@AndrewKemendo Govts don't need to follow normal laws. They will obtain AI developed by companies at gunpoint,\n",
            "====================\n",
            "humans: The universe is prob littered w/ the 1-planet graves of cultures which made the sensible economic \n",
            "====================\n",
            "humans.\n",
            "@Boltfinger Click the left scroll wheel to pause or mute music\n",
            "@c12elong Yes\n",
            "@Jbourquat True\n",
            "@c12elong Drive like crazy if you like loud music\n",
            "@SpaceX Hyperloop tube vision test footage from earlier today. Not in the works yet.\n",
            "@ID_AA_Carmack Full performance video of Falcon 9 launch. Not in yet. Early access.\n",
            "RT @SpaceX: Falcon 9 has successfully deployed Falcon 9 into its geostationary transfer orbit. Weather is good today, but tomorrow? \n",
            "====================\n",
            "humans. I love you too! \n",
            "====================\n",
            "humans and Mars?\n",
            "@VoltzCoreAudio @andygen21 @Teslarati A 9m diameter vehicle fits in our existing factories ...\n",
            "@andygen21 @Teslarati Yes, I postponed publishing in order to present the updated interplanetary rocket & spaceship? https://t.co/eyTev6VyTw\n",
            "Discussing physics of tunnels with Mayor Vargas (who has a physics background). Hawthorne support for The Boring Co? https://t.co/Doh7qwm8DM\n",
            "RT @Teslarati: SpaceX skipping Red Dragon for ?vastly bigger ships? on Mars https://t.co/8Re70QsYSI https://t.co/fyJ\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=150,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=50,\n",
        "                      batch_size=5\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}